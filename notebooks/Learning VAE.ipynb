{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download mnist and make a generator from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not actually going to test on GPU but it should work or at least give you an idea of how to make it work on CPU and GPU (which I'm not a fan of in oytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define an encoder and a decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_size, h_size, z_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_size, h_size)\n",
    "        self.mu_gen = nn.Linear(h_size, z_size)\n",
    "        # make the output to be the logarithm \n",
    "        # i.e will have to take the exponent\n",
    "        # which forces variance to be positive\n",
    "        # not that this is the diagonal of the covariance\n",
    "        self.log_var_gen = nn.Linear(h_size, z_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.mu_gen(x)\n",
    "        log_var = self.log_var_gen(x)\n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_size, h_size, z_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_size, h_size)\n",
    "        self.fc3 = nn.Linear(h_size, x_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # black and white MNIST => sigmoid for each pixel\n",
    "        x = torch.sigmoid(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VAE is simply a container of the encoder + decoder + reparametrization trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_size, h_size, z_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.z_size = z_size\n",
    "        self.encoder = Encoder(x_size, h_size, z_size)\n",
    "        self.decoder = Decoder(x_size, h_size, z_size)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var) # square root in exponent => std\n",
    "        eps = torch.randn_like(std)\n",
    "        z = std * eps + mu\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make image linear (i.e vector form)\n",
    "        x = x.view(-1, self.x_size)\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 28 * 28 # mnist image\n",
    "h_size = 256\n",
    "z_size = 16\n",
    "model = VAE(x_size, h_size, z_size).to(device) # migrates to CUDA if you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (mu_gen): Linear(in_features=256, out_features=16, bias=True)\n",
       "    (log_var_gen): Linear(in_features=256, out_features=16, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc1): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_hat, x, mu, log_var, beta=1):\n",
    "    \"\"\"Compute the ELBO loss\"\"\"\n",
    "    x_size = x_hat.size(-1)\n",
    "    # black or white image => use sigmoid for each pixel\n",
    "    rec_loss = F.binary_cross_entropy(x_hat, x.view(-1, x_size), reduction='sum')\n",
    "    # closed form solution for gaussian prior and posterior\n",
    "    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    vae_loss = rec_loss + beta * kl_div\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer=optim.Adam, loss_function=loss_function):\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer(self.model.parameters())\n",
    "        self.loss_function = loss_function\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __call__(self, train, test, n_epochs=10):\n",
    "        self.epoch = 0\n",
    "        for _ in range(n_epochs):\n",
    "            self._train_epoch(train)\n",
    "            self._test_epoch(test)\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, self.model.z_size).to(device)\n",
    "                sample = model.decoder(sample).cpu()  # make sure on cpu\n",
    "                save_image(sample.view(64, 1, 28, 28),\n",
    "                           '../results/sample_' + str(self.epoch) + '.png')\n",
    "        \n",
    "    def _train_epoch(self, train):\n",
    "        self.epoch += 1\n",
    "        model.train() # make sure train mode (e.g. dropout)\n",
    "        train_loss = 0\n",
    "        for i, (x, _) in enumerate(train):\n",
    "            x = x.to(device) # data on GPU \n",
    "            self.optimizer.zero_grad() # reset all previous gradients\n",
    "            x_hat, mu, log_var = model(x)\n",
    "            loss = self.loss_function(x_hat, x, mu, log_var)\n",
    "            loss.backward() # backpropagate (i.e store gradients)\n",
    "            train_loss += loss.item() # compute loss (.item because only the value)\n",
    "            self.optimizer.step() # take optimizing step (~gradient descent)\n",
    "\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(\n",
    "              self.epoch, train_loss / len(train.dataset)))\n",
    "        \n",
    "    def _test_epoch(self, test):\n",
    "        model.eval() # make sure evaluate mode (e.g. dropout)\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():  # stop gradients computation\n",
    "            for i, (x, _) in enumerate(test):\n",
    "                x = x.to(device)\n",
    "                x_hat, mu, log_var = model(x)\n",
    "                test_loss += loss_function(x_hat, x, mu, log_var).item()\n",
    "\n",
    "        print('Test loss: {:.4f}'.format(test_loss/len(test.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 543.5655\n",
      "Test loss: 543.4254\n",
      "Epoch: 2 Train loss: 543.4148\n",
      "Test loss: 543.3198\n",
      "Epoch: 3 Train loss: 543.3404\n",
      "Test loss: 543.2177\n",
      "Epoch: 4 Train loss: 543.2585\n",
      "Test loss: 543.1621\n",
      "Epoch: 5 Train loss: 543.2243\n",
      "Test loss: 543.1746\n",
      "Epoch: 6 Train loss: 543.2243\n",
      "Test loss: 543.1531\n",
      "Epoch: 7 Train loss: 543.2111\n",
      "Test loss: 543.1439\n",
      "Epoch: 8 Train loss: 543.2008\n",
      "Test loss: 543.1417\n",
      "Epoch: 9 Train loss: 543.1977\n",
      "Test loss: 543.1113\n",
      "Epoch: 10 Train loss: 543.1822\n",
      "Test loss: 543.1046\n",
      "CPU times: user 8min 17s, sys: 8.42 s, total: 8min 25s\n",
      "Wall time: 15min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in more details I actually wrote a quick post about VAE in the last days: https://yanndubs.github.io/machine-learning-glossary/#variational-autoencoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
